# -*- coding: utf-8 -*-
"""XGboost

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19lkQHD4khd6oYFhdkzwv1wz8qUA8jNdP
"""

import pandas as pd
import numpy as np
import nltk
import re
import torch
import joblib
from transformers import AutoTokenizer, AutoModel
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from transformers import BertTokenizer, BertModel

# Acces to google drive for dataset

from google.colab import drive
drive.mount('/content/drive')

import joblib
import torch
import numpy as np
from transformers import BertTokenizer, BertModel
import os  # Dosyayı silmek için

# Model ve LabelEncoder'ı yükleme
def load_model_and_encoder(model_path="/content/drive/MyDrive/xgboost_bert_model.pkl",
                           encoder_path="/content/drive/MyDrive/label_encoder.pkl"):
    model = joblib.load(model_path)
    label_encoder = joblib.load(encoder_path)
    print(f"Model yüklendi: {model_path}")
    print(f"LabelEncoder yüklendi: {encoder_path}")
    return model, label_encoder

# BERT ile tek metin embedding oluşturup geçici olarak .npy dosyasına kaydet
def save_bert_embedding(text, save_path="user_input_emb.npy", model_name='dbmdz/bert-base-turkish-cased'):
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertModel.from_pretrained(model_name)
    model.eval()

    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)

    with torch.no_grad():
        outputs = model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :].numpy()

    np.save(save_path, embeddings)

# Embedding dosyasından tahmin yap
def predict_from_embedding(embedding_path, model, label_encoder):
    embedding = np.load(embedding_path)
    prediction = model.predict(embedding)
    predicted_label = label_encoder.inverse_transform(prediction)[0]
    return predicted_label

# Metni al, embed et, tahmin et, sonra embedding dosyasını sil
if __name__ == "__main__":
    xgboost_model, label_encoder = load_model_and_encoder()

    user_input = input("")

    temp_embedding_path = "user_input_emb.npy"

    try:
        # Geçici embedding oluştur
        save_bert_embedding(user_input, save_path=temp_embedding_path)

        # Tahmin yap
        predicted_class = predict_from_embedding(temp_embedding_path, xgboost_model, label_encoder)

        print(f"Girilen metin '{predicted_class}' sınıfına aittir.")
    finally:
        # Dosyayı sil
        if os.path.exists(temp_embedding_path):
            os.remove(temp_embedding_path)